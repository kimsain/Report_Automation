"""
LangChain ê¸°ë°˜ ì„ë² ë”© ìœ í‹¸ë¦¬í‹°

ì´ ëª¨ë“ˆì€ LangChainì˜ OpenAIEmbeddingsë¥¼ í™œìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import os
import json
import psycopg2
import numpy as np
from typing import List, Dict, Any, Optional
from tqdm import tqdm
from langchain.embeddings import OpenAIEmbeddings
from langchain.schema import Document
from langchain_config import LangChainConfig

# OpenAI API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = LangChainConfig.OPENAI_API_KEY

class LangChainEmbeddingUtils:
    """
    LangChain ê¸°ë°˜ ì„ë² ë”© ìœ í‹¸ë¦¬í‹° í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """ì„ë² ë”© ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”"""
        self.db_params = LangChainConfig.get_db_connection_params()
        self.embeddings = OpenAIEmbeddings(
            model=LangChainConfig.OPENAI_EMBEDDING_MODEL,
            openai_api_key=LangChainConfig.OPENAI_API_KEY
        )
    
    def connect_to_db(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°"""
        return psycopg2.connect(**self.db_params)
    
    def generate_embeddings_from_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ ì„ë² ë”© ìƒì„±"""
        conn = self.connect_to_db()
        cursor = conn.cursor()
        
        # ëŒ€ìƒ í…Œì´ë¸” ì •ì˜ ë° ë°ì´í„° ì¶”ì¶œ ì¿¼ë¦¬
        tables = {
            "festival_stats": """
                SELECT r.region_code, f.period_type, f.visitors, f.sales_amount, 
                       f.main_age_group, f.main_business_type 
                FROM festival_stats f 
                JOIN regions r ON f.region_id = r.id
            """,
            "population_stats": """
                SELECT r.region_code, p.gender, p.age_group, p.period_type, p.visitors 
                FROM population_stats p 
                JOIN regions r ON p.region_id = r.id
            """,
            "sales_stats": """
                SELECT r.region_code, s.business_type, s.sales_amount 
                FROM sales_stats s 
                JOIN regions r ON s.region_id = r.id
            """,
            "hourly_stats": """
                SELECT r.region_code, h.period_type, h.time_period, h.visitors, h.sales_amount 
                FROM hourly_stats h 
                JOIN regions r ON h.region_id = r.id
            """,
            "inflow_stats": """
                SELECT r.region_code, i.inflow_region_code, i.visitors, i.inflow_type, 
                       i.region_name, i.province_name 
                FROM inflow_stats i 
                JOIN regions r ON i.region_id = r.id
            """
        }
        
        try:
            # ê¸°ì¡´ ì„ë² ë”© ë°ì´í„° ì‚­ì œ
            cursor.execute("DELETE FROM embedding_store")
            conn.commit()
            
            # ê° í…Œì´ë¸”ì—ì„œ ë°ì´í„° ì¶”ì¶œ ë° ì„ë² ë”© ì €ì¥
            for table, query in tables.items():
                print(f"\nğŸ“‚ {table} í…Œì´ë¸”ì—ì„œ ë¬¸ì¥ ìƒì„± ë° ì„ë² ë”© ì¤‘...")
                cursor.execute(query)
                rows = cursor.fetchall()
                
                documents = []
                for row in tqdm(rows, desc=f"Processing {table}"):
                    # ë¬¸ì¥ ìƒì„± ë¡œì§
                    text, metadata = self._generate_text_and_metadata(table, row)
                    if text:
                        documents.append(Document(page_content=text, metadata=metadata))
                
                # ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± ë° ì €ì¥
                if documents:
                    self._save_embeddings_batch(cursor, table, documents)
                    conn.commit()
                    print(f"âœ… {table} í…Œì´ë¸” ì™„ë£Œ. ì €ì¥ëœ ë¬¸ì¥ ìˆ˜: {len(documents)}")
            
            print("\nğŸ‰ ëª¨ë“  í…Œì´ë¸” ì„ë² ë”© ì™„ë£Œ")
            
        except Exception as e:
            print(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            conn.rollback()
        finally:
            cursor.close()
            conn.close()
    
    def _generate_text_and_metadata(self, table: str, row: tuple) -> tuple:
        """í…Œì´ë¸”ë³„ ë¬¸ì¥ ìƒì„± ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
        if table == "festival_stats":
            text = f"ì˜ì—­ {row[0]}ì˜ {row[1]} ê¸°ê°„: ë°©ë¬¸ì ìˆ˜ {row[2]}ëª…, ë§¤ì¶œ {row[3]}ì–µ, ì£¼ìš” ì—°ë ¹ì¸µ {row[4]}, ì£¼ ë§¤ì¶œ ì—…ì¢…: {row[5]}"
            metadata = {"region_code": row[0], "period_type": row[1], "table": table}
            
        elif table == "population_stats":
            text = f"{row[0]} ì§€ì—­ {row[1]} {row[2]}ì˜ {row[3]} ë°©ë¬¸ê° ìˆ˜ëŠ” {row[4]}ëª…ì…ë‹ˆë‹¤."
            metadata = {"region_code": row[0], "gender": row[1], "age_group": row[2], "period_type": row[3], "table": table}
            
        elif table == "sales_stats":
            text = f"{row[0]} ì§€ì—­ì˜ {row[1]} ì—…ì¢… ë§¤ì¶œì€ {row[2]}ì…ë‹ˆë‹¤."
            metadata = {"region_code": row[0], "business_type": row[1], "table": table}
            
        elif table == "hourly_stats":
            text = f"{row[0]} ì§€ì—­ {row[1]} ì‹œê°„ëŒ€({row[2]}) ë°©ë¬¸ê° ìˆ˜ëŠ” {row[3]}ëª…ì´ê³  ë§¤ì¶œì€ {row[4]}ì…ë‹ˆë‹¤."
            metadata = {"region_code": row[0], "period_type": row[1], "time_period": row[2], "table": table}
            
        elif table == "inflow_stats":
            text = f"{row[5]} {row[4]}ì—ì„œ ìœ ì…ëœ ì¸êµ¬ëŠ” {row[2]}ëª…ì´ë©° ìœ ì…ìœ í˜•ì€ {row[3]}ì…ë‹ˆë‹¤."
            metadata = {"region_code": row[0], "inflow_type": row[3], "region_name": row[4], "table": table}
            
        else:
            return None, None
        
        return text, metadata
    
    def _save_embeddings_batch(self, cursor, table: str, documents: List[Document]):
        """ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± ë° ì €ì¥"""
        # í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        texts = [doc.page_content for doc in documents]
        
        # LangChainì„ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”© ìƒì„±
        embeddings = self.embeddings.embed_documents(texts)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        for doc, embedding in zip(documents, embeddings):
            cursor.execute("""
                INSERT INTO embedding_store (table_name, original_text, metadata, embedding)
                VALUES (%s, %s, %s, %s)
            """, (table, doc.page_content, json.dumps(doc.metadata), embedding))
    
    def search_similar_documents(self, query: str, k: int = 5) -> List[Dict[str, Any]]:
        """ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰"""
        conn = self.connect_to_db()
        cursor = conn.cursor()
        
        try:
            # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
            query_embedding = self.embeddings.embed_query(query)
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰
            cursor.execute("""
                SELECT original_text, metadata, 
                       1 - (embedding <=> %s::vector) as similarity
                FROM embedding_store
                ORDER BY embedding <=> %s::vector
                LIMIT %s
            """, (query_embedding, query_embedding, k))
            
            results = []
            for row in cursor.fetchall():
                results.append({
                    "text": row[0],
                    "metadata": row[1],
                    "similarity": float(row[2])
                })
            
            return results
            
        except Exception as e:
            print(f"ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
        finally:
            cursor.close()
            conn.close()
    
    def get_embedding_statistics(self) -> Dict[str, Any]:
        """ì„ë² ë”© í†µê³„ ì •ë³´ ë°˜í™˜"""
        conn = self.connect_to_db()
        cursor = conn.cursor()
        
        try:
            cursor.execute("""
                SELECT table_name, COUNT(*) as count
                FROM embedding_store
                GROUP BY table_name
                ORDER BY count DESC
            """)
            
            table_stats = {}
            total_count = 0
            for row in cursor.fetchall():
                table_stats[row[0]] = row[1]
                total_count += row[1]
            
            return {
                "total_embeddings": total_count,
                "table_statistics": table_stats,
                "embedding_model": LangChainConfig.OPENAI_EMBEDDING_MODEL,
                "vector_dimension": LangChainConfig.VECTOR_DIMENSION
            }
            
        except Exception as e:
            print(f"í†µê³„ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {}
        finally:
            cursor.close()
            conn.close()

if __name__ == "__main__":
    utils = LangChainEmbeddingUtils()
    utils.generate_embeddings_from_database()

